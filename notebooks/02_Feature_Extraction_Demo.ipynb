{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57e125cd",
   "metadata": {},
   "source": [
    "# 02: Feature Inspection\n",
    "\n",
    "This notebook loads and visualizes the features generated by `src/feature_extraction.py` and stored in `data/features/`.\n",
    "\n",
    "We will:\n",
    "1.  Load a sample feature file (`.npy`).\n",
    "2.  Visualize the **Mel Spectrogram**.\n",
    "3.  Visualize the **Pitch Contour (F0)**.\n",
    "4.  Visualize the **MFCCs**.\n",
    "\n",
    "This confirms the features are correctly calculated and stored before we use them for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a34a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "\n",
    "# --- Configuration ---\n",
    "sns.set_style(\"whitegrid\")\n",
    "FEATURES_DIR = Path(\"../data/features\")\n",
    "REPORTS_PLOTS_DIR = Path(\"../reports/plots\")\n",
    "REPORTS_PLOTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Assuming a sample rate of 16000 Hz and hop length of 256 for time-axis display\n",
    "SR = 16000\n",
    "HOP_LENGTH = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5bd982",
   "metadata": {},
   "source": [
    "## 1. Load Sample Feature File\n",
    "\n",
    "Let's find the first available `.npy` file in the features directory and load it. We assume it's a dictionary containing all feature types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780e6698",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sample_features(base_dir: Path):\n",
    "    \"\"\"Finds and loads the first .npy file from the directory.\"\"\"\n",
    "    sample_path = next(base_dir.rglob(\"*.npy\"), None)\n",
    "    if sample_path:\n",
    "        print(f\"Loading sample: {sample_path.name}\")\n",
    "        # allow_pickle=True is needed if the .npy file contains a Python dictionary\n",
    "        features = np.load(sample_path, allow_pickle=True).item()\n",
    "        return features, sample_path.name\n",
    "    else:\n",
    "        print(f\"Error: No feature files found in {base_dir}\")\n",
    "        return None, None\n",
    "\n",
    "features, sample_name = load_sample_features(FEATURES_DIR)\n",
    "\n",
    "if features:\n",
    "    print(\"\\nLoaded feature keys:\")\n",
    "    print(list(features.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c26fd57",
   "metadata": {},
   "source": [
    "## 2. Visualize Mel Spectrogram\n",
    "\n",
    "This is the primary input to the model's encoder. We expect to see clear speech formants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b4899c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if features and 'mel_spectrogram' in features:\n",
    "    mel_spec = features['mel_spectrogram']\n",
    "    print(f\"Mel Spectrogram shape: {mel_spec.shape}\") # (n_mels, n_frames)\n",
    "    \n",
    "    plt.figure(figsize=(15, 4))\n",
    "    # We display the spectrogram in dB\n",
    "    S_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "    librosa.display.specshow(S_db, sr=SR, hop_length=HOP_LENGTH, x_axis='time', y_axis='mel')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title(f\"Mel Spectrogram - {sample_name}\")\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Frequency (Hz)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(REPORTS_PLOTS_DIR / \"02_sample_melspectrogram.png\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Key 'mel_spectrogram' not found in feature file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d640d4",
   "metadata": {},
   "source": [
    "## 3. Visualize Pitch Contour (F0)\n",
    "\n",
    "This visualizes the fundamental frequency (pitch) of the speaker over time. We expect to see values of 0 during unvoiced segments (silence, 's', 'f' sounds)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023b12ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "if features and 'pitch_contour' in features:\n",
    "    f0 = features['pitch_contour']\n",
    "    print(f\"Pitch Contour shape: {f0.shape}\") # (n_frames,)\n",
    "\n",
    "    plt.figure(figsize=(15, 4))\n",
    "    # Get time axis ticks\n",
    "    times = librosa.times_like(f0, sr=SR, hop_length=HOP_LENGTH)\n",
    "    \n",
    "    # Set 0 values (unvoiced) to NaN so they don't plot\n",
    "    f0[f0 == 0] = np.nan\n",
    "    \n",
    "    plt.plot(times, f0, 'o', markersize=2, label='F0 (Hz)')\n",
    "    plt.title(f\"Pitch Contour (F0) - {sample_name}\")\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Frequency (Hz)\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(REPORTS_PLOTS_DIR / \"02_sample_pitch_contour.png\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Key 'pitch_contour' not found in feature file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab91987",
   "metadata": {},
   "source": [
    "## 4. Visualize MFCCs\n",
    "\n",
    "MFCCs (Mel-Frequency Cepstral Coefficients) are another common feature, often used for speaker and accent identification. They capture the timbral quality of the voice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353806f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if features and 'mfcc' in features:\n",
    "    mfccs = features['mfcc']\n",
    "    print(f\"MFCC shape: {mfccs.shape}\") # (n_mfcc, n_frames)\n",
    "    \n",
    "    plt.figure(figsize=(15, 4))\n",
    "    librosa.display.specshow(mfccs, sr=SR, hop_length=HOP_LENGTH, x_axis='time')\n",
    "    plt.colorbar(label='Coefficient Value')\n",
    "    plt.title(f\"MFCCs - {sample_name}\")\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"MFCC Coefficient\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(REPORTS_PLOTS_DIR / \"02_sample_mfccs.png\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Key 'mfcc' not found in feature file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86961081",
   "metadata": {},
   "source": [
    "## 5. Initial Findings\n",
    "\n",
    "The feature files in `data/features/` appear to be structured correctly as Python dictionaries.\n",
    "\n",
    "* **Mel Spectrogram:** The visualization shows clear harmonic structures, indicating the feature is valid.\n",
    "* **Pitch Contour:** The F0 plot correctly shows voiced segments and unvoiced gaps (where F0=0).\n",
    "* **MFCCs:** The cepstral coefficients are loaded correctly.\n",
    "\n",
    "All features seem to be aligned in time (i.e., they have the same number of frames) and are ready for the training pipeline."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
