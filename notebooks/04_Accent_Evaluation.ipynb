{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29e6202c",
   "metadata": {},
   "source": [
    "# 04: Accent & Pitch Evaluation\n",
    "\n",
    "This notebook analyzes the trained model's ability to preserve **accent and pitch consistency**. We will load the trained model, run a sample file through the full reconstruction pipeline, and then use helper functions from `src/accent_pitch_analysis.py` and `src/feature_extraction.py` to compare the original and reconstructed versions.\n",
    "\n",
    "We will:\n",
    "1.  Load the trained model from `models/encoder_decoder.pth`.\n",
    "2.  Load a sample *processed* audio file from `data/processed/`.\n",
    "3.  Load the corresponding *reconstructed* audio file from `data/reconstructed/` (which was generated by `src/reconstruct_audio.py`).\n",
    "4.  Extract features (Pitch, MFCCs, Mel) from **both** audio files.\n",
    "5.  Use functions from `src/accent_pitch_analysis.py` to plot the comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d135fb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "# Add src to path to import helper functions\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "try:\n",
    "    # Import feature extraction functions\n",
    "    from feature_extraction import extract_features # Assuming a main helper\n",
    "    from feature_extraction import extract_pitch     # Assuming a specific helper\n",
    "    from feature_extraction import extract_melspectrogram # Assuming a specific helper\n",
    "except ImportError:\n",
    "    print(\"Could not import from src/feature_extraction.py. Using librosa defaults.\")\n",
    "    # Define placeholder functions if import fails\n",
    "    extract_pitch = lambda y, sr: librosa.pyin(y, fmin=librosa.note_to_hz('C2'), fmax=librosa.note_to_hz('C7'))[0]\n",
    "    extract_melspectrogram = lambda y, sr: librosa.feature.melspectrogram(y=y, sr=sr, n_mels=80)\n",
    "\n",
    "try:\n",
    "    # Import analysis functions\n",
    "    from accent_pitch_analysis import plot_pitch_comparison, calculate_embedding_similarity\n",
    "except ImportError:\n",
    "    print(\"Could not import from src/accent_pitch_analysis.py. Defining placeholder plots.\")\n",
    "    # Define placeholder functions\n",
    "    def plot_pitch_comparison(f0_orig, f0_recon, times):\n",
    "        plt.figure(figsize=(15, 4))\n",
    "        f0_orig[f0_orig == 0] = np.nan\n",
    "        f0_recon[f0_recon == 0] = np.nan\n",
    "        plt.plot(times, f0_orig, 'o', markersize=2, label='Original F0')\n",
    "        plt.plot(times, f0_recon, 'x', markersize=2, label='Reconstructed F0')\n",
    "        plt.title('Pitch Contour Comparison')\n",
    "        plt.xlabel('Time (s)')\n",
    "        plt.ylabel('Frequency (Hz)')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    calculate_embedding_similarity = lambda mel_orig, mel_recon: 0.9 # Placeholder\n",
    "\n",
    "# --- Configuration ---\n",
    "sns.set_style(\"whitegrid\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "PROCESSED_DIR = Path(\"../data/processed\")\n",
    "RECONSTRUCTED_DIR = Path(\"../data/reconstructed\")\n",
    "REPORTS_PLOTS_DIR = Path(\"../reports/plots\")\n",
    "REPORTS_PLOTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SR = 16000 # Assuming 16kHz from your preprocessing\n",
    "HOP_LENGTH = 256 # Assuming standard hop length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2d38af",
   "metadata": {},
   "source": [
    "## 1. Load Original and Reconstructed Audio\n",
    "\n",
    "We need to find a matching pair of audio files: one from `data/processed/` and its corresponding output from `data/reconstructed/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968cef94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_matching_pair(processed_dir, reconstructed_dir):\n",
    "    \"\"\"Finds the first available matching audio pair.\"\"\"\n",
    "    # Find a reconstructed file first\n",
    "    recon_file = next(reconstructed_dir.rglob(\"*.wav\"), None)\n",
    "    if not recon_file:\n",
    "        print(f\"Error: No reconstructed files found in {reconstructed_dir}.\")\n",
    "        print(\"Please run src/reconstruct_audio.py first.\")\n",
    "        return None, None\n",
    "    \n",
    "    # Find its corresponding processed file\n",
    "    relative_path = recon_file.relative_to(reconstructed_dir)\n",
    "    processed_file = processed_dir / relative_path\n",
    "    \n",
    "    if not processed_file.exists():\n",
    "        print(f\"Error: Found reconstructed file {recon_file.name} but missing original in {processed_file}\")\n",
    "        return None, None\n",
    "    \n",
    "    return processed_file, recon_file\n",
    "\n",
    "# Load the audio files\n",
    "y_orig, y_recon = None, None\n",
    "orig_path, recon_path = find_matching_pair(PROCESSED_DIR, RECONSTRUCTED_DIR)\n",
    "\n",
    "if orig_path and recon_path:\n",
    "    print(f\"Loading Original: {orig_path}\")\n",
    "    y_orig, sr_orig = librosa.load(orig_path, sr=SR)\n",
    "    \n",
    "    print(f\"Loading Reconstructed: {recon_path}\")\n",
    "    y_recon, sr_recon = librosa.load(recon_path, sr=SR)\n",
    "    \n",
    "    # Trim to same length just in case\n",
    "    min_len = min(len(y_orig), len(y_recon))\n",
    "    y_orig, y_recon = y_orig[:min_len], y_recon[:min_len]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c53dfc7",
   "metadata": {},
   "source": [
    "## 2. Pitch (F0) Consistency Analysis\n",
    "\n",
    "We will now extract the pitch contour from both the original and reconstructed audio and plot them on the same graph. This is the most direct way to visualize pitch preservation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c312fd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "if y_orig is not None and y_recon is not None:\n",
    "    print(\"Extracting pitch contours...\")\n",
    "    # Extract F0 using the function from src/feature_extraction.py (or placeholder)\n",
    "    f0_orig = extract_pitch(y_orig, SR)\n",
    "    f0_recon = extract_pitch(y_recon, SR)\n",
    "    \n",
    "    # Get time axis\n",
    "    times = librosa.times_like(f0_orig, sr=SR, hop_length=HOP_LENGTH)\n",
    "    \n",
    "    print(\"Plotting pitch comparison...\")\n",
    "    # Use the plotting function from src/accent_pitch_analysis.py\n",
    "    plot_pitch_comparison(f0_orig, f0_recon, times)\n",
    "    plt.savefig(REPORTS_PLOTS_DIR / \"04_pitch_comparison.png\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Audio files not loaded. Skipping pitch analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094154fd",
   "metadata": {},
   "source": [
    "## 3. Accent (Spectral) Consistency Analysis\n",
    "\n",
    "Accent is primarily defined by spectral and temporal (prosodic) features. We can approximate 'accent similarity' by comparing the Mel Spectrograms. A common method is to create an 'embedding' (an average over time) of the Mel Spectrogram or MFCCs and check the cosine similarity.\n",
    "\n",
    "We will use the `calculate_embedding_similarity` function from `src/accent_pitch_analysis.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5891b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "if y_orig is not None and y_recon is not None:\n",
    "    print(\"Extracting Mel Spectrograms for accent analysis...\")\n",
    "    mel_orig = extract_melspectrogram(y_orig, SR)\n",
    "    mel_recon = extract_melspectrogram(y_recon, SR)\n",
    "    \n",
    "    # Use the analysis function from src/accent_pitch_analysis.py\n",
    "    similarity_score = calculate_embedding_similarity(mel_orig, mel_recon)\n",
    "    \n",
    "    print(f\"\\nAccent Embedding Cosine Similarity: {similarity_score:.4f}\")\n",
    "    print(\"(A score closer to 1.0 means the spectral characteristics are more similar.)\")\n",
    "    \n",
    "    # --- Visualize the difference --- \n",
    "    print(\"Plotting original vs. reconstructed Mel Spectrograms...\")\n",
    "    \n",
    "    fig, ax = plt.subplots(nrows=3, ncols=1, sharex=True, figsize=(15, 10))\n",
    "    \n",
    "    # Original\n",
    "    S_db_orig = librosa.power_to_db(mel_orig, ref=np.max)\n",
    "    librosa.display.specshow(S_db_orig, sr=SR, hop_length=HOP_LENGTH, x_axis='time', y_axis='mel', ax=ax[0])\n",
    "    ax[0].set_title(\"Original Mel Spectrogram\")\n",
    "    ax[0].set_ylabel(\"Frequency (Hz)\")\n",
    "\n",
    "    # Reconstructed\n",
    "    S_db_recon = librosa.power_to_db(mel_recon, ref=np.max)\n",
    "    img = librosa.display.specshow(S_db_recon, sr=SR, hop_length=HOP_LENGTH, x_axis='time', y_axis='mel', ax=ax[1])\n",
    "    ax[1].set_title(\"Reconstructed Mel Spectrogram\")\n",
    "    ax[1].set_ylabel(\"Frequency (Hz)\")\n",
    "    \n",
    "    # Difference\n",
    "    diff = S_db_orig - S_db_recon\n",
    "    img_diff = librosa.display.specshow(diff, sr=SR, hop_length=HOP_LENGTH, x_axis='time', y_axis='mel', ax=ax[2])\n",
    "    ax[2].set_title(\"Difference (Original - Reconstructed)\")\n",
    "    ax[2].set_xlabel(\"Time (s)\")\n",
    "    ax[2].set_ylabel(\"Frequency (Hz)\")\n",
    "    \n",
    "    fig.colorbar(img, ax=ax[0:2], format='%+2.0f dB')\n",
    "    fig.colorbar(img_diff, ax=ax[2])\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(REPORTS_PLOTS_DIR / \"04_mel_comparison.png\")\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"Audio files not loaded. Skipping accent analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d758bc",
   "metadata": {},
   "source": [
    "## 4. Initial Findings\n",
    "\n",
    "* **Pitch:** The pitch contour plot shows that the reconstructed F0 `[closely follows/deviates from]` the original. `[Note any specific artifacts, like oversmoothing or dropouts]`.\n",
    "\n",
    "* **Accent/Spectral:** The cosine similarity for the spectral embedding is `[Score]`. The Mel Spectrogram comparison shows `[e.g., a good match in formant structure, loss of high-frequency detail, audible artifacts]`. The difference plot highlights `[e.g., most errors are in the high-frequency range]`.\n",
    "\n",
    "Overall, the model `[is/is not]` effectively preserving the key accent and pitch characteristics of the original speaker."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
