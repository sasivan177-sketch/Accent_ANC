{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01: Exploratory Data Analysis\n",
    "\n",
    "This notebook focuses on understanding the raw dataset, its metadata, and the properties of the processed audio files. It **does not** perform any new feature extraction or training.\n",
    "\n",
    "We will:\n",
    "1.  Load and analyze the metadata (`train.csv`).\n",
    "2.  Check the distribution of speakers and accents.\n",
    "3.  Load a sample of *processed* audio files (`data/processed/`) to analyze their duration and sample rate.\n",
    "4.  Visualize a sample waveform and Mel Spectrogram to confirm data quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "\n",
    "# Import utils if it has plotting helpers (assuming it might)\n",
    "try:\n",
    "    import sys\n",
    "    sys.path.append('../src')\n",
    "    import utils\n",
    "except ImportError:\n",
    "    print(\"src/utils.py not found or has no plotting helpers. Using standard plots.\")\n",
    "\n",
    "# --- Configuration ---\n",
    "sns.set_style(\"whitegrid\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "RAW_DATA_DIR = Path(\"../data/raw\")\n",
    "PROCESSED_DATA_DIR = Path(\"../data/processed\")\n",
    "REPORTS_PLOTS_DIR = Path(\"../reports/plots\")\n",
    "\n",
    "# Ensure plots directory exists\n",
    "REPORTS_PLOTS_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Metadata\n",
    "\n",
    "First, let's load the metadata file to see what information we have about each audio clip. We'll assume the main metadata file is `train.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_path = RAW_DATA_DIR / \"train.csv\"\n",
    "\n",
    "if not metadata_path.exists():\n",
    "    print(f\"Error: Metadata file not found at {metadata_path}\")\n",
    "    # Create a dummy dataframe if file not found, to allow notebook to run\n",
    "    df = pd.DataFrame(columns=['file_path', 'speaker', 'accent', 'duration_sec'])\n",
    "else:\n",
    "    df = pd.read_csv(metadata_path)\n",
    "\n",
    "print(f\"Loaded metadata with {len(df)} entries.\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Analyze Metadata Distribution\n",
    "\n",
    "Let's check the distribution of key columns, like `speaker` or `accent` (if they exist)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values per column:\")\n",
    "print(df.isna().sum())\n",
    "\n",
    "# Check unique values for categorical columns\n",
    "if 'speaker' in df.columns:\n",
    "    print(f\"\\nTotal unique speakers: {df['speaker'].nunique()}\")\n",
    "    \n",
    "if 'accent' in df.columns:\n",
    "    print(f\"Total unique accents: {df['accent'].nunique()}\")\n",
    "    \n",
    "    # Plot accent distribution\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.countplot(y=df['accent'], order=df['accent'].value_counts().index)\n",
    "    plt.title(\"Distribution of Accents in the Dataset\")\n",
    "    plt.xlabel(\"Number of Samples\")\n",
    "    plt.ylabel(\"Accent\")\n",
    "    plt.savefig(REPORTS_PLOTS_DIR / \"01_accent_distribution.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Analyze Processed Audio Properties\n",
    "\n",
    "The metadata might not have audio properties like duration. Let's load a sample of the *processed* audio files from `data/processed/` to get their duration and sample rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio_properties(file_path: Path):\n",
    "    \"\"\"Loads an audio file and returns its duration and sample rate.\"\"\"\n",
    "    try:\n",
    "        y, sr = librosa.load(file_path, sr=None)\n",
    "        duration = librosa.get_duration(y=y, sr=sr)\n",
    "        return {'duration_sec': duration, 'sample_rate': sr}\n",
    "    except Exception as e:\n",
    "        print(f\"Could not load {file_path.name}: {e}\")\n",
    "        return {'duration_sec': None, 'sample_rate': None}\n",
    "\n",
    "# Get file paths from the 'file_path' column\n",
    "# We assume paths in CSV are relative to the project root, e.g., \"data/raw/train/file.wav\"\n",
    "# We need to map them to the processed directory\n",
    "# Let's sample 500 files to speed this up\n",
    "sample_size = min(500, len(df))\n",
    "file_properties = []\n",
    "\n",
    "print(f\"Analyzing properties of {sample_size} processed audio files...\")\n",
    "for idx, row in tqdm(df.sample(sample_size).iterrows(), total=sample_size):\n",
    "    # Construct the path to the processed file\n",
    "    # Assumes processed files are flat or in speaker dirs: data/processed/speaker/file.wav\n",
    "    # We take just the filename from the raw path\n",
    "    raw_path = Path(row['file_path'])\n",
    "    \n",
    "    # This logic depends on your data_preprocessing.py\n",
    "    # Assuming \"data/processed/{speaker}/{filename}\"\n",
    "    if 'speaker' in df.columns:\n",
    "        processed_path = PROCESSED_DATA_DIR / row['speaker'] / raw_path.name\n",
    "    else:\n",
    "        # Fallback if no speaker column\n",
    "        processed_path = PROCESSED_DATA_DIR / raw_path.name\n",
    "        \n",
    "    if processed_path.exists():\n",
    "        props = get_audio_properties(processed_path)\n",
    "        props['id'] = row.get('id', raw_path.stem) # Get a unique ID\n",
    "        file_properties.append(props)\n",
    "\n",
    "props_df = pd.DataFrame(file_properties).set_index('id')\n",
    "df = df.join(props_df, on=df['file_path'].apply(lambda x: Path(x).stem))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Plot Audio Duration Distribution\n",
    "\n",
    "Now we can visualize the distribution of audio clip lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any files we couldn't load\n",
    "df_clean = df.dropna(subset=['duration_sec'])\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(df_clean['duration_sec'], bins=50, kde=True)\n",
    "plt.title(\"Distribution of Audio Durations (in seconds)\")\n",
    "plt.xlabel(\"Duration (sec)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.savefig(REPORTS_PLOTS_DIR / \"01_duration_distribution.png\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Audio Duration Stats (seconds):\")\n",
    "print(df_clean['duration_sec'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Check Sample Rates\n",
    "\n",
    "Let's confirm all processed files have the same sample rate (e.g., 16000 Hz) as defined in `data_preprocessing.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "sns.countplot(x=df_clean['sample_rate'])\n",
    "plt.title(\"Sample Rate of Processed Files\")\n",
    "plt.xlabel(\"Sample Rate (Hz)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.savefig(REPORTS_PLOTS_DIR / \"01_sample_rate_distribution.png\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nSample Rate Counts:\")\n",
    "print(df_clean['sample_rate'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualize a Sample Waveform and Spectrogram\n",
    "\n",
    "Finally, let's load one of the processed audio files to visualize its waveform and a standard Mel Spectrogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a sample file to load (use the first valid one from our props_df)\n",
    "if not props_df.empty:\n",
    "    sample_id = props_df.index[0]\n",
    "    \n",
    "    # Reconstruct the file path\n",
    "    # This assumes 'id' in props_df matches the filename stem\n",
    "    # We need to find the full path from the original df\n",
    "    \n",
    "    try:\n",
    "        # Find the original row\n",
    "        original_row = df[df['file_path'].str.contains(sample_id)].iloc[0]\n",
    "        \n",
    "        # Construct processed path\n",
    "        if 'speaker' in df.columns:\n",
    "            sample_path = PROCESSED_DATA_DIR / original_row['speaker'] / f\"{sample_id}.wav\"\n",
    "        else:\n",
    "            sample_path = PROCESSED_DATA_DIR / f\"{sample_id}.wav\"\n",
    "\n",
    "        print(f\"Loading sample file: {sample_path}\")\n",
    "        y, sr = librosa.load(sample_path, sr=None) # Load with its native SR\n",
    "\n",
    "        print(f\"Sample Rate: {sr} Hz, Duration: {len(y)/sr:.2f}s\")\n",
    "\n",
    "        # --- Plot Waveform ---\n",
    "        plt.figure(figsize=(15, 4))\n",
    "        librosa.display.waveshow(y, sr=sr)\n",
    "        plt.title(f\"Waveform - {sample_path.name}\")\n",
    "        plt.xlabel(\"Time (s)\")\n",
    "        plt.ylabel(\"Amplitude\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(REPORTS_PLOTS_DIR / \"01_sample_waveform.png\")\n",
    "        plt.show()\n",
    "\n",
    "        # --- Plot Mel Spectrogram ---\n",
    "        # Use parameters from your feature_extraction.py (assuming 80 mels)\n",
    "        S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=80)\n",
    "        S_db = librosa.power_to_db(S, ref=np.max)\n",
    "\n",
    "        plt.figure(figsize=(15, 4))\n",
    "        librosa.display.specshow(S_db, sr=sr, x_axis='time', y_axis='mel')\n",
    "        plt.colorbar(format='%+2.0f dB')\n",
    "        plt.title(f\"Mel Spectrogram - {sample_path.name}\")\n",
    "        plt.xlabel(\"Time (s)\")\n",
    "        plt.ylabel(\"Frequency (Hz)\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(REPORTS_PLOTS_DIR / \"01_sample_melspectrogram.png\")\n",
    "        plt.show()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Could not load or plot sample file: {e}\")\n",
    "else:\n",
    "    print(\"No valid processed files found to visualize.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Initial Findings\n",
    "\n",
    "*(This section would be filled in after running the notebook)*\n",
    "\n",
    "* **Metadata:** The dataset contains `[Number]` entries, `[X]` unique speakers, and `[Y]` unique accents. The accent `[Accent Name]` is the most common.\n",
    "* **Audio Properties:** All processed audio files are confirmed to be at **`[Sample Rate]` Hz**, which matches the preprocessing target.\n",
    "* **Duration:** The audio clips have a mean duration of `[Mean Duration]` seconds, with most files falling between `[Min]` and `[Max]` seconds. This consistency is good for training.\n",
    "* **Quality:** The sample waveform appears clean and normalized (amplitude is within a standard range), and the spectrogram shows clear speech components.\n",
    "\n",
    "This EDA confirms that the raw data is well-understood and the output of `src/data_preprocessing.py` is correctly formatted for the next step, feature extraction."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}